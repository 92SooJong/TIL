# 2023-11-08

Databricks JDBC를 통한 Bulk insert가 올바르게 작동하지 않는 문제가 있었음.

아래 링크 보고 배치 사이즈를 1000개로 변경 해봄.
- https://www.baeldung.com/spring-jdbc-batch-inserts

배치사이즈를 키운다고 해서 무조건 성능이 좋아지는 건 아님. Oracle JDBC에서는 100개 정도를 추천하고 있음. (100개로 줄여도 건 by 건으로 insert 되는건 해결하지 못함)

HikariCP에서 setAutoCommit을 false 세팅하기
- 그런 옵션 기능은 제공하지 않는다고 Databricks Jdbc에서 출력함.
- 결국 AutoCommit을 false로 할 수 있어야 Bulk insert가 가능함. 

# 2023-11-09

1. HikariCP대신 Basic Datasource를 적용해 봤지만 auto commit을 false로 하는데 실패했다.
2. 추가로 JDBC databricks를 대신해서 Oracle이나 MySQL 드라이버를 적용해 봤지만 auto commit을 false로 하는데 실패했다.
3. 결국은 auto commit을 하지 않는 방법을 찾아야했는데 insert문을 수정하는 것으로 문제를 해결했다.
   1. `단건 insert 쿼리 -> commit -> 단건 insert 쿼리 -> commit 방식`을 `다건 insert 쿼리 -> commit -> 다건 insert 쿼리 -> commit`으로 변경했다.
   2. 한번에 전송하는 데이터량이 많아지는것을 방지하기 위해 쿼리를 요청할때 100건을 넘기지 않도록 했다.