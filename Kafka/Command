[] 프로듀서 생성
./bin/kafka-console-producer.sh --broker-list zk-server1:9092 --topic sample-topic1

[] 컨슈머 생성
./bin/kafka-console-consumer.sh --bootstrap-server zk-server1:9092 --topic jdbc-connector-user --from-beginning

[] 카프카 서버실행
./bin/kafka-server-start.sh config/server.properties

[] 주키퍼 실행
./bin/zookeeper-server-start.sh config/zookeeper.properties

[] 커넥터 실행 ( 소스커넥터인듯 하다. )
bin/connect-standalone.sh config/connect-standalone.properties connector1.properties

[] topic 생성
bin/kafka-topics.sh --create --topic sample-topic1 --bootstrap-server zk-server1:9092 --create --replication-factor 3 --partitions 3

[] topic 제거
bin/kafka-topics.sh --delete --zookeeper zk-server1:2181 --topic _connect-offsets

[] topic 조회 
bin/kafka-topics.sh --list  --bootstrap-server zk-server1:9092  --topic jdbc-connector-user

[] connect 오프셋 컨슘
./bin/kafka-console-consumer.sh --bootstrap-server zk-server1:9092 --topic connect-offsets --from-beginning --property print.key=true

[] connect 오프셋 초기화
echo '["jdbc_source_mariadb_01",{"protocol":"1","table":"mydatabase.user"}]#' | ./bin/kafka-console-producer.sh --bootstrap-server zk-server1:9092 --topic connect-offsets --property "parse.key=true" --property "key.separator=#"


echo '["jdbc_source_mariadb_01",{"protocol":"1","table":"mydatabase.user"}]#'	{"incrementing":15}
echo '["demo",{"query":"query"}]#' 


[] jdbc connector 다운로드
confluent-hub install confluentinc/kafka-connect-jdbc:10.1.1 --component-dir /home/soojong2/connect/component --worker-configs /home/soojong2/connect/connect.properties

[] 포트의미
2181포트는 카프카 서버와 ZooKeeper와 소통하기 위한 것
9092포트는 Consumer와 Producer가 Kafka 서버와 통신하기 위한 것

[] 분산모드로 워커 실행
./bin/connect-distributed.sh config/connect-distributed.properties

[] kafka offset 확인
./kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9192 --topic jdbc-connect-user --time -1



[] 커넥터 실행
curl -X POST http://localhost:8083/connectors -H "Content-Type: application/json" -d '{ 
	"name": "jdbc_source_mariadb_01",
	"config": { "connector.class": "io.confluent.connect.jdbc.JdbcSourceConnector",
			"connection.url": "jdbc:mysql://192.168.131.1:3306/mydatabase",
			"connection.user": "root",
			"connection.password": "root",
			"topic.prefix": "jdbc-connector-",
			"poll.interval.ms" : 2000,
			"table.whitelist" : "user",
			"mode":"incrementing",
			"incrementing.column.name": "id",
			"topic.creation.default.replication.factor": 1,
			"topic.creation.default.partitions" : 1
												
		   }
}'

curl -X DELETE http://localhost:8083/connectors/jdbc_source_mariadb_01


https://docs.confluent.io/kafka-connect-jdbc/current/source-connector/source_config_options.html#



curl -X POST http://localhost:8083/connectors -H "Content-Type: application/json" -d @/home/soojong2/connect/connector/user-source-connector.json



bin/kafka-topics.sh --delete --zookeeper zk-server1:2181 --topic connect-configs,connect-offsets,connect-status,jdbc-connector-user


kafkacat -b zk-server1:9092 -t connect-offsets -C -f '\n Key (%K bytes): %k \n Value (%S bytes): %s \n Timestamp: %T \n Partition: %p \n Offset: %o\n'

kafkacat -b zk-server1:9092 -t jdbc-connector-user -P -Z -K# -p 2

echo '["jdbc_source_connector",{"protocol":"1","table":"mydatabase.user"}]#' | kafkacat -b zk-server1:9092 -t connect-offsets -P -Z -K# -p 19

kafkacat -b localhost:9092 -t _connect-offsets -C -K#
